{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\python38\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\python38\\lib\\site-packages (from textblob) (3.6.3)\n",
      "Requirement already satisfied: joblib in c:\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex in c:\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (2021.10.8)\n",
      "Requirement already satisfied: click in c:\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\python38\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "\n",
    "#python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\lipi_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lipi_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lipi_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\lipi_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\lipi_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\lipi_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TextBlob('I Love NLP, not you!')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'Love', 'NLP', 'not', 'you'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"I Love NLP, not you!\")]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['love nlp'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['election commission', 'assam', 'bjp', 'himanta biswa sarma', 'assam', 'sarma', 'opposition leader', 'hagrama mohilary', 'bodoland', \"people 's\", 'front', 'ec', 'sarma'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "text3 = \"\"\"\n",
    "The Election Commission on Friday debarred Assam Minister and BJP leader Himanta Biswa Sarma from campaigning for ongoing Assam elections for 48 hours with effect from today. This came after Sarma allegedly made threatening remarks against opposition leader Hagrama Mohilary of the Bodoland People's Front. EC had on Thursday asked Sarma for an explanation by today over his remarks.\n",
    "\"\"\"\n",
    "TextBlob(text3).noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-08bf97f7a786>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mblob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Something is better than nothing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\textblob\\blob.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, from_lang, to)\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mBaseBlob\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mBaseBlob\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \"\"\"\n\u001b[1;32m--> 546\u001b[1;33m         return self.__class__(self.translator.translate(self.raw,\n\u001b[0m\u001b[0;32m    547\u001b[0m                               from_lang=from_lang, to_lang=to))\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\textblob\\translate.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, source, from_lang, to_lang, host, type_)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mtk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_calculate_tk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         )\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\textblob\\translate.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, url, host, type_, data)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhost\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_proxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             response = self.parent.error(\n\u001b[0m\u001b[0;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "blob = TextBlob('Something is better than nothing')\n",
    "blob.translate(to='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('weather', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('sunny', 'JJ'),\n",
       " ('today', 'NN')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = TextBlob('The weather is sunny today!')\n",
    "sent.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = Word('history')\n",
    "q.stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Went'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word('Went')\n",
    "w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history\n"
     ]
    }
   ],
   "source": [
    "print(q.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word' object has no attribute 'definition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-0cccd6cf5b68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mWord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Circle'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Word' object has no attribute 'definition'"
     ]
    }
   ],
   "source": [
    "Word('Circle').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Classification System: this all works behind the scene we just have to use the libraries\n",
    "#loading data and creating a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data should be given like list of tuples\n",
    "train = [\n",
    "     ('I love this sandwich.', 'pos'),\n",
    "     ('this is an amazing place!', 'pos'),\n",
    "     ('I feel very good about these beers.', 'pos'),\n",
    "     ('this is my best work.', 'pos'),\n",
    "     (\"what an awesome view\", 'pos'),\n",
    "     ('I do not like this restaurant', 'neg'),\n",
    "     ('I am tired of this stuff.', 'neg'),\n",
    "     (\"I can't deal with this\", 'neg'),\n",
    "     ('he is my sworn enemy!', 'neg'),\n",
    "     ('my boss is horrible.', 'neg'),\n",
    "    ('my boss is bad.','neg')\n",
    "]\n",
    "\n",
    "test = [\n",
    "     ('the beer was good.', 'pos'),\n",
    "     ('I do not enjoy my job', 'neg'),\n",
    "     (\"I ain't feeling dandy today.\", 'neg'),\n",
    "     (\"I feel amazing!\", 'pos'),\n",
    "     ('Gary is a friend of mine.', 'pos'),\n",
    "     (\"I can't believe I'm doing this.\", 'neg')\n",
    "]\n",
    "\n",
    "#call a classifier\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-54ebba220e2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#call a classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifiers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.classify('movie was not bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retraining of the model\n",
    "#new data in form of list and tuples only\n",
    "new_data = [\n",
    "     ('the beer was good.', 'pos'),\n",
    "     ('I do not enjoy my job', 'neg'),\n",
    "     (\"I ain't feeling dandy today.\", 'neg'),\n",
    "     (\"I feel amazing!\", 'pos')]\n",
    "    \n",
    "cl.update(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\python38\\\\Lib\\\\site-packages\\\\charset_normalizer\\\\assets\\\\__init__.py'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading spacy-3.1.3-cp38-cp38-win_amd64.whl (12.0 MB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp38-cp38-win_amd64.whl (112 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.1-cp38-cp38-win_amd64.whl (451 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp38-cp38-win_amd64.whl (36 kB)\n",
      "Collecting jinja2\n",
      "  Downloading Jinja2-3.0.2-py3-none-any.whl (133 kB)\n",
      "Collecting requests<3.0.0,>=2.13.0\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp38-cp38-win_amd64.whl (21 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp38-cp38-win_amd64.whl (6.5 MB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\n",
      "Collecting numpy>=1.15.0\n",
      "  Downloading numpy-1.21.2-cp38-cp38-win_amd64.whl (14.0 MB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\python38\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: setuptools in c:\\python38\\lib\\site-packages (from spacy) (41.2.0)\n",
      "Collecting thinc<8.1.0,>=8.0.9\n",
      "  Downloading thinc-8.0.10-cp38-cp38-win_amd64.whl (1.0 MB)\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-21.0-py3-none-any.whl (40 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Using cached spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.7-py3-none-any.whl (38 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Requirement already satisfied: colorama in c:\\python38\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\python38\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.2)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.0.1-cp38-cp38-win_amd64.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, numpy, murmurhash, cymem, catalogue, wasabi, urllib3, typer, srsly, smart-open, pyparsing, pydantic, preshed, MarkupSafe, idna, charset-normalizer, certifi, blis, thinc, spacy-legacy, requests, pathy, packaging, jinja2, spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\python38\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.62.3)\n",
      "Requirement already satisfied: jinja2 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (41.2.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.26.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.21.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\python38\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\python38\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python38\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\python38\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\python38\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python38\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.1.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = \"\"\" The Republican president is being challenged by Democratic Party \n",
    "nominee Joe Biden, who is best known as Barack Obama’s vice-president but has been in US \n",
    "politics since the 1970s.As election day approaches, pollingcompanies will be trying to gauge \n",
    "the mood of the nation by asking voters which candidate they prefer.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Republican president is being challenged by Democratic Party \n",
      "nominee Joe Biden, who is best known as Barack Obama’s vice-president but has been in US \n",
      "politics since the 1970s.As election day approaches, pollingcompanies will be trying to gauge \n",
      "the mood of the nation by asking voters which candidate they prefer.\n"
     ]
    }
   ],
   "source": [
    "print(doc)\n",
    "#stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "#text = \"\"\" The Republican president is being challenged by Democratic Party nominee Joe Biden, who is best known as Barack Obama’s vice-president but has been in US politics since the 1970s.As election day approaches, pollingcompanies will be trying to gauge the mood of the nation by asking voters which candidate they prefer.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'‘s', 'side', 'few', 'hereupon', 'per', \"'re\", 'besides', 'whenever', 'then', 'itself', 'to', 'either', 'have', 'due', 'that', 'both', 'or', 'hereby', 'move', 'from', 'often', 'while', 'before', 'indeed', 'using', 'show', 'used', 'made', 'first', 'whither', 'their', 'meanwhile', 'whole', 'should', 'elsewhere', 'bottom', 'latterly', 'anyhow', 'empty', 'there', 'ca', 'herein', 'afterwards', 'once', 'together', 'after', 'namely', 'eleven', 'whatever', 'many', 'just', 'yourselves', 'ours', 'whoever', 'what', 'really', '‘ve', 'through', 'therefore', 'give', 'among', 'could', 'wherein', 'than', 'ten', 'get', 'also', 'has', 'throughout', 'everyone', 'something', 'anyway', \"'ve\", '’ve', 'beforehand', 'its', 'somewhere', 'down', 'quite', 'several', 'where', 'whereafter', 'doing', 'hers', 'most', 'herself', 'into', 'fifty', 'against', 'although', 'serious', 'you', 'only', 'ourselves', 'these', 'still', 'hundred', 'because', 'in', 'myself', 'thus', 'former', 'third', 'were', 'becoming', 'be', '‘d', 'me', 'does', 'might', 'seemed', 'been', '’ll', 'is', 'sometime', 'nevertheless', 'those', 'will', 'though', 'become', 'whose', 'least', 'none', 'somehow', 'put', 're', 'five', 'being', 'became', 'n‘t', 'say', 'am', 'during', 'all', 'other', 'as', 'thereupon', 'nor', 'on', 'an', 'almost', 'make', '‘re', 'at', 'under', 'whence', 'whereas', 'we', 'mine', 'further', 'now', \"'m\", 'noone', 'unless', 'keep', 'he', 'rather', 'please', '’m', 'hereafter', 'own', \"'s\", 'without', 'themselves', 'yourself', 'any', 'sixty', 'becomes', 'three', '‘m', 'nothing', 'neither', 'when', 'below', 'of', 'wherever', 'nine', 'upon', 'regarding', 'so', 'twelve', 'do', 'one', 'she', 'them', 'enough', 'above', 'anywhere', 'thru', 'whom', 'same', 'the', 'whereupon', 'him', 'front', 'your', 'his', 'four', 'did', 'never', 'towards', 'across', 'mostly', 'except', 'up', 'over', 'forty', 'n’t', 'however', 'by', 'fifteen', 'various', 'her', 'seems', 'had', 'yet', 'if', 'which', 'not', \"n't\", 'done', 'two', 'with', 'latter', 'else', 'since', 'moreover', 'less', 'onto', 'about', 'therein', 'full', 'such', 'us', 'well', 'eight', 'even', '‘ll', 'are', 'sometimes', 'anyone', 'out', 'next', 'along', 'this', 'top', 'another', 'yours', 'my', 'himself', \"'d\", 'i', 'nowhere', 'our', 'six', 'formerly', 'it', 'no', 'last', 'off', 'here', 'beside', 'but', 'until', '’re', 'already', 'around', 'name', 'much', 'ever', 'twenty', 'via', 'must', 'nobody', 'some', 'whether', 'someone', 'seeming', 'within', 'amongst', 'can', 'each', 'perhaps', 'why', 'thereby', 'seem', 'between', 'may', 'others', 'more', 'behind', 'again', '’d', 'thence', 'and', 'anything', 'who', 'whereby', 'call', 'a', 'would', 'how', 'thereafter', 'always', 'was', 'too', \"'ll\", 'alone', 'amount', 'toward', 'very', 'go', 'see', 'everywhere', 'for', 'beyond', 'part', '’s', 'take', 'they', 'hence', 'back', 'every', 'cannot', 'everything', 'otherwise'}\n"
     ]
    }
   ],
   "source": [
    "# to remove the stop words:\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'The', 'Republican', 'president', 'is', 'being', 'challenged', 'by', 'Democratic', 'Party', '\\n', 'nominee', 'Joe', 'Biden', ',', 'who', 'is', 'best', 'known', 'as', 'Barack', 'Obama', '’s', 'vice', '-', 'president', 'but', 'has', 'been', 'in', 'US', '\\n', 'politics', 'since', 'the', '1970s', '.', 'As', 'election', 'day', 'approaches', ',', 'pollingcompanies', 'will', 'be', 'trying', 'to', 'gauge', '\\n', 'the', 'mood', 'of', 'the', 'nation', 'by', 'asking', 'voters', 'which', 'candidate', 'they', 'prefer', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  The Republican president is being challenged by Democratic Party \\n nominee Joe Biden , who is best known as Barack Obama ’s vice - president but has been in US \\n politics since the 1970s . As election day approaches , pollingcompanies will be trying to gauge \\n the mood of the nation by asking voters which candidate they prefer .'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ls = [token for token in doc if token not in stopwords]\n",
    "# print(ls)\n",
    "\n",
    "a = []\n",
    "for token in doc:\n",
    "  if token not in stopwords:\n",
    "    a.append(str(token))\n",
    "print(a)\n",
    "\" \".join(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.lang.en import English\n",
    "\n",
    "# nlp = English()\n",
    "\n",
    "# x = nlp(text)\n",
    "\n",
    "# token_list = []\n",
    "# for token in x:\n",
    "#     token_list.append(token.text)\n",
    "\n",
    "# from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "\n",
    "# filtered_sentence =[] \n",
    "\n",
    "# for word in token_list:\n",
    "#     y = nlp.vocab[word]\n",
    "#     if y.is_stop == False:\n",
    "#         filtered_sentence.append(word) \n",
    "  \n",
    "\n",
    "# print(\" \".join(filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function to remove stop words and punctuation from text and return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token in doc: \n",
    "#     if not token.is_stop: \n",
    "#         print(token)\n",
    "\n",
    "# for token in doc: \n",
    "#     if not token.is_punct: \n",
    "#         print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_pun(text):\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        clean_data = []\n",
    "        if not token.is_stop:\n",
    "            if not token.is_punct:\n",
    "                clean_data.append(str(token))\n",
    "            \n",
    "    return \"\" \"\".join(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_pun( \"\"\" The Republican president is being challenged by Democratic Party \n",
    "nominee Joe Biden, who is best known as Barack Obama’s vice-president but has been in US \n",
    "politics since the 1970s.As election day approaches, pollingcompanies will be trying to gauge \n",
    "the mood of the nation by asking voters which candidate they prefer.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ----->  \n",
      "The -----> the\n",
      "Republican -----> republican\n",
      "president -----> president\n",
      "is -----> be\n",
      "being -----> be\n",
      "challenged -----> challenge\n",
      "by -----> by\n",
      "Democratic -----> Democratic\n",
      "Party -----> Party\n",
      "\n",
      " -----> \n",
      "\n",
      "nominee -----> nominee\n",
      "Joe -----> Joe\n",
      "Biden -----> Biden\n",
      ", -----> ,\n",
      "who -----> who\n",
      "is -----> be\n",
      "best -----> well\n",
      "known -----> know\n",
      "as -----> as\n",
      "Barack -----> Barack\n",
      "Obama -----> Obama\n",
      "’s -----> ’s\n",
      "vice -----> vice\n",
      "- -----> -\n",
      "president -----> president\n",
      "but -----> but\n",
      "has -----> have\n",
      "been -----> be\n",
      "in -----> in\n",
      "US -----> US\n",
      "\n",
      " -----> \n",
      "\n",
      "politics -----> politic\n",
      "since -----> since\n",
      "the -----> the\n",
      "1970s -----> 1970\n",
      ". -----> .\n",
      "As -----> as\n",
      "election -----> election\n",
      "day -----> day\n",
      "approaches -----> approach\n",
      ", -----> ,\n",
      "pollingcompanies -----> pollingcompanie\n",
      "will -----> will\n",
      "be -----> be\n",
      "trying -----> try\n",
      "to -----> to\n",
      "gauge -----> gauge\n",
      "\n",
      " -----> \n",
      "\n",
      "the -----> the\n",
      "mood -----> mood\n",
      "of -----> of\n",
      "the -----> the\n",
      "nation -----> nation\n",
      "by -----> by\n",
      "asking -----> ask\n",
      "voters -----> voter\n",
      "which -----> which\n",
      "candidate -----> candidate\n",
      "they -----> they\n",
      "prefer -----> prefer\n",
      ". -----> .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token,'----->',token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -----> _SP -----> SPACE\n",
      "The -----> DT -----> DET\n",
      "Republican -----> JJ -----> ADJ\n",
      "president -----> NN -----> NOUN\n",
      "is -----> VBZ -----> AUX\n",
      "being -----> VBG -----> AUX\n",
      "challenged -----> VBN -----> VERB\n",
      "by -----> IN -----> ADP\n",
      "Democratic -----> NNP -----> PROPN\n",
      "Party -----> NNP -----> PROPN\n",
      "\n",
      " -----> _SP -----> SPACE\n",
      "nominee -----> NN -----> NOUN\n",
      "Joe -----> NNP -----> PROPN\n",
      "Biden -----> NNP -----> PROPN\n",
      ", -----> , -----> PUNCT\n",
      "who -----> WP -----> PRON\n",
      "is -----> VBZ -----> AUX\n",
      "best -----> RBS -----> ADV\n",
      "known -----> VBN -----> VERB\n",
      "as -----> IN -----> ADP\n",
      "Barack -----> NNP -----> PROPN\n",
      "Obama -----> NNP -----> PROPN\n",
      "’s -----> POS -----> PART\n",
      "vice -----> NN -----> NOUN\n",
      "- -----> NN -----> NOUN\n",
      "president -----> NN -----> NOUN\n",
      "but -----> CC -----> CCONJ\n",
      "has -----> VBZ -----> AUX\n",
      "been -----> VBN -----> VERB\n",
      "in -----> IN -----> ADP\n",
      "US -----> NNP -----> PROPN\n",
      "\n",
      " -----> _SP -----> SPACE\n",
      "politics -----> NNS -----> NOUN\n",
      "since -----> IN -----> SCONJ\n",
      "the -----> DT -----> DET\n",
      "1970s -----> NNS -----> NOUN\n",
      ". -----> . -----> PUNCT\n",
      "As -----> IN -----> ADP\n",
      "election -----> NN -----> NOUN\n",
      "day -----> NN -----> NOUN\n",
      "approaches -----> VBZ -----> VERB\n",
      ", -----> , -----> PUNCT\n",
      "pollingcompanies -----> NNS -----> NOUN\n",
      "will -----> MD -----> AUX\n",
      "be -----> VB -----> AUX\n",
      "trying -----> VBG -----> VERB\n",
      "to -----> TO -----> PART\n",
      "gauge -----> VB -----> VERB\n",
      "\n",
      " -----> _SP -----> SPACE\n",
      "the -----> DT -----> DET\n",
      "mood -----> NN -----> NOUN\n",
      "of -----> IN -----> ADP\n",
      "the -----> DT -----> DET\n",
      "nation -----> NN -----> NOUN\n",
      "by -----> IN -----> ADP\n",
      "asking -----> VBG -----> VERB\n",
      "voters -----> NNS -----> NOUN\n",
      "which -----> WDT -----> DET\n",
      "candidate -----> NN -----> NOUN\n",
      "they -----> PRP -----> PRON\n",
      "prefer -----> VBP -----> VERB\n",
      ". -----> . -----> PUNCT\n"
     ]
    }
   ],
   "source": [
    "#like_email, like_url is another functions in spacy\n",
    "#pos tagging\n",
    "for token in doc:\n",
    "    print(token,'----->',token.tag_,'----->',token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'punctuation mark, sentence closer'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spacy.explain() to explain pos tags\n",
    "spacy.explain(token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speech to text library: speech recognition\n",
    "#pip install SpeechRecognition\n",
    "#https://pypi.org/project/SpeechRecognition/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
